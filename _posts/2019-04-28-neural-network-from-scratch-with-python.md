### Имплементация компьютерной нейронной сети с помощью Python  
{% include math.html %}
Всем привет. [В предыдущей статье](https://vkhvorostianyi.github.io/2019/04/14/logistic-regression-and-regularization.html) уже было упомянуто о том, что функция сигмоиды может использоваться как фукция активации компьютерной "нейронной сети", сегодня рассмотрим алгоритм "нейронки" более подробно. Компьютерная "нейронная сеть" (Computer Neural Network) является алгоритмом машинного обучения, который за своим принципом напоминает работу нейронной сети человека, звучит немного страшновато, на практике просто. В двух словах условный "нейрон" - это функция (активации), которая принимает и отдает сигналы.

Изображение "нейрона" (математическая модель парсептрона)
![img](/assets/neuron.png)

Нейроны-функции обьеденяются в слои, слоев может быть много и не очень (например алгоритм логистической регресии можно репрезентовать как нейронную сеть с одного нейрона). Слои расделяют на входной, скрытый и выходной, при этом нейронная сеть с одним скрытым (внутренним) слоем будет називатся однослойной.  
Виглядит это примерно так:  

![img](/assets/neuronnaya-set.gif)

Нужно добавить, что рассматриваемая нейронная сеть относится к типу "обучение с учителем" (supervised learning) и решает задачу классификации. 


#### Функция активации

Как было сказано выше, функция сигмоиды часто используется как функция активации в нейронных сетях, наряду с гиперболическим тангенсои и ReLU.

Ниже дана формула сигмоиды (в качестве примера степенной функции взята линейная регрессия):

$$z^{(i)} = w^T x^{(i)} + b $$
 
$$\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})$$

$$sigmoid(z^{(i)}) = \frac{1}{1-e^{-z^{(i)}}}$$



Где   
$$z^{(i)}$$ - степенная функция (линейная регрессия)  
$$\hat{y}^{(i)}$$ - гипотеза   
$$sigmoid(z^{(i)})$$ - сигмоида 

Графики различных ф-ций активации:  

![img](/assets/actviation_func.png)



#### Прямое распространение (Forward Propagation)
