### Имплементация компьютерной нейронной сети с помощью Python  
{% include math.html %}
Всем привет. [В предыдущей статье](https://vkhvorostianyi.github.io/2019/04/14/logistic-regression-and-regularization.html) уже было упомянуто о том, что функция сигмоиды может использоваться как фукция активации компьютерной "нейронной сети", сегодня рассмотрим алгоритм "нейронки" более подробно. Компьютерная "нейронная сеть" (Computer Neural Network) является алгоритмом машинного обучения, который за своим принципом напоминает работу нейронной сети человека, звучит немного страшновато,но на практике все не так уж сложно. В двух словах условный "нейрон", это просто функция (активации), которая принимает и отдает сигналы.

![img](/assets/neuron.png)

Эти нейроны-функции обьеденяются в слои, слоев может быть много и не очень (например алгоритм логистической регресии можно репрезентовать как нейронную сеть с одного нейрона). Слои расделяют на входной, скрытый и выходной, при этом нейронная сеть с одним скрытым (внутренним) слоем будет називатся однослойной.  
Виглядит это примерно так:  

![img](/assets/neuronnaya-set.gif)

Нужно добавить, что рассматриваемая нейронная сеть относится к типу "обучение с учителем" (supervised learning) и решает задачу классификации. 


#### Функция активации

Как было сказано выше, функция сигмоиды часто используется как функция активации в нейронных сетях, наряду с гиперболическим тангенсои и ReLU.

$$z^{(i)} = w^T x^{(i)} + b $$
 
$$\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})$$

$$sigmoid(z^{(i)}) = \frac{1}{1-e^{-z^{(i)}}}$$



Где   
$$z^{(i)}$$ - функция прямой (линейная регрессия)  
$$\hat{y}^{(i)}$$ - гипотеза   
$$sigmoid(z^{(i)})$$ - сигмоида 

![img](/assets/log_reg.png)

