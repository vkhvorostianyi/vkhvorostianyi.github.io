### Имплементация компьютерной нейронной сети с помощью Python  
{% include math.html %}
Всем привет. [В предыдущей статье](https://vkhvorostianyi.github.io/2019/04/14/logistic-regression-and-regularization.html) уже было упомянуто о том, что функция сигмоиды может использоваться как фукция активации компьютерной "нейронной сети", сегодня рассмотрим алгоритм "нейронки" более подробно. Компьютерная "нейронная сеть" (Computer Neural Network) является алгоритмом машинного обучения, который за своим принципом напоминает работу нейронной сети человека. В двух словах условный "нейрон" - это функция (активации), которая принимает и отдает сигналы.

Изображение "нейрона" (математическая модель парсептрона)
![img](/assets/neuron.png)

Нейроны-функции обьеденяются в слои, слоев может быть много и не очень, их расделяют на входной, скрытый(скрытые) и выходной, при этом нейронная сеть с одним скрытым (внутренним) слоем будет називатся однослойной.  
Виглядит это примерно так:  

![img](/assets/neuronnaya-set.gif)

Нужно добавить, что рассматриваемая нейронная сеть относится к типу "обучение с учителем" (supervised learning) и решает задачу классификации. 


#### Функция активации

Рассмотрим некоторые популярные функции активации.

*Сигмоида*

Как было сказано выше, функция сигмоиды часто используется как функция активации в нейронных сетях, наряду с гиперболическим тангенсои и ReLU(о которых поговорим ниже).

Ниже дана формула сигмоиды (в качестве примера степенной функции взята линейная регрессия):

$$z^{(i)} = w^T x^{(i)} + b $$
 
$$\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})$$

$$sigmoid(z^{(i)}) = \frac{1}{1-e^{-z^{(i)}}}$$


Где   
$$z^{(i)}$$ - степенная функция (линейная регрессия)  
$$\hat{y}^{(i)}$$ - гипотеза   
$$sigmoid(z^{(i)})$$ - сигмоида 

Графичек:
![img](/assets/sigmoid.png)

Преимущества сигмоиды:
- Гладкость: Имеет производную в любой точке, что является важным фактором при использовании метода градиетного спуска
- Чуствительна к малейшим изменениям $x$ на участке от [-2;2], что позволяет четко провести границу между классами.
- Значения $y$ всегда находятся в диапазоне [0,1]

Графики различных ф-ций активации:  

![img](/assets/actviation_func.png)


#### Прямое распространение (Forward Propagation)  

Прямое распостранение - это собстевенно, пропуск данных через мясорубку скрытых слоев нейронов.
